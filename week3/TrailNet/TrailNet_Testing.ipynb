{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets ,transforms\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images from the folder and set the folder name as labels\n",
    "\n",
    "train_data = datasets.ImageFolder(\n",
    "    'Lane_data/train_data',\n",
    "    transform = transforms.Compose([transforms.ToTensor()])                         \n",
    ")\n",
    "\n",
    "test_data = datasets.ImageFolder(\n",
    "    'Lane_data/test_data',\n",
    "    transform = transforms.Compose([transforms.ToTensor()])                         \n",
    ")\n",
    "#\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=20,shuffle= True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=20,shuffle=True)\n",
    "\n",
    "#show labels\n",
    "print(train_data.classes)\n",
    "print(train_data.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Net Work Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.conv1 = nn.Sequential(              \n",
    "            nn.Conv2d(\n",
    "                in_channels=3,              \n",
    "                out_channels=32,            \n",
    "                kernel_size=4,              \n",
    "                stride=1,                   \n",
    "                padding=0,                  \n",
    "            ),                                                 \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=32,\n",
    "                kernel_size=4,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "            ),                           \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                \n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=32,\n",
    "                kernel_size=4,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "            ),                           \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                \n",
    "        )\n",
    "        self.conv4 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=32,\n",
    "                kernel_size=4,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),                           \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                \n",
    "        )\n",
    "        self.fc1 = nn.Linear(34048, 200)\n",
    "        self.fc2 = nn.Linear(200, 3)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = CNN_Model().cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10): # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the input\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap time in Variable\n",
    "        inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 0:   # print every 20 mini-batches\n",
    "            print('[%d, %d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy testing...')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in test_loader:\n",
    "    images, labels = data\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    with torch.no_grad():\n",
    "        outputs = net(Variable(images))\n",
    "        _,predicted = torch.max(outputs.data,1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.cpu().numpy()\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "test_single_loader = torch.utils.data.DataLoader(test_data, batch_size=1,shuffle=True)\n",
    "\n",
    "dataiter = iter(test_single_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.cuda()\n",
    "labels = labels.cuda()\n",
    "outputs = net(Variable(images))\n",
    "_,predicted = torch.max(outputs.data,1)\n",
    "\n",
    "if labels == 0:\n",
    "    print('Image Label:L')\n",
    "if labels == 1:\n",
    "    print('Image Label:R')\n",
    "if labels == 2:\n",
    "    print('Image Label:S')\n",
    "if predicted == 0:\n",
    "    print('Predicted Label:L')\n",
    "if predicted == 1:\n",
    "    print('Predicted Label:R')\n",
    "if predicted == 2:\n",
    "    print('Predicted Label:S')\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'trailnet.pth') # Save state_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
